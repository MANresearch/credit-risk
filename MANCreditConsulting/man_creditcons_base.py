# -*- coding: utf-8 -*-
"""MAN_CreditCons_BASE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KUBCftENeuCRQPIKLKrZq13DNfmcRT6S
"""

!pip install shap xgboost streamlit streamlit_shap plotly streamlit_option_menu --quiet

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# --- 1. Geração de Dados Fictícios ---
print("1. Gerando dados fictícios para simulação...")
np.random.seed(42) # Para reprodutibilidade

n_samples = 10000

# Variáveis numéricas
idade = np.random.randint(18, 70, n_samples)
renda_mensal = np.random.normal(5000, 2000, n_samples).round(2)
divida_existente = np.random.normal(15000, 7000, n_samples).round(2)
score_serasa = np.random.randint(300, 900, n_samples)
tempo_emprego_meses = np.random.randint(0, 240, n_samples)
num_emprestimos_ativos = np.random.randint(0, 5, n_samples)

# Variáveis categóricas
genero = np.random.choice(['Masculino', 'Feminino'], n_samples)
estado_civil = np.random.choice(['Solteiro', 'Casado', 'Divorciado', 'Viúvo'], n_samples)
escolaridade = np.random.choice(['Fundamental', 'Médio', 'Superior', 'Pós-graduação'], n_samples, p=[0.1, 0.3, 0.4, 0.2])
tipo_moradia = np.random.choice(['Alugada', 'Propria', 'Financiada'], n_samples)

# Geração da variável alvo (inadimplência - 'default')
# Vamos criar uma lógica simples onde renda mais baixa, dívida alta e score baixo aumentam a chance de default
prob_default = (1 / (1 + np.exp(
    - (
        0.0005 * (3000 - renda_mensal) + # Renda baixa aumenta prob
        0.0001 * divida_existente +    # Dívida alta aumenta prob
        0.005 * (500 - score_serasa) + # Score baixo aumenta prob
        np.random.normal(0, 0.5, n_samples) # Ruído
    )
)))

default = (np.random.rand(n_samples) < prob_default).astype(int)

# Criar DataFrame
df = pd.DataFrame({
    'idade': idade,
    'renda_mensal': np.maximum(500, renda_mensal), # Renda mínima de 500
    'divida_existente': np.maximum(0, divida_existente), # Dívida mínima de 0
    'score_serasa': score_serasa,
    'tempo_emprego_meses': tempo_emprego_meses,
    'num_emprestimos_ativos': num_emprestimos_ativos,
    'genero': genero,
    'estado_civil': estado_civil,
    'escolaridade': escolaridade,
    'tipo_moradia': tipo_moradia,
    'default': default # 1 para inadimplente, 0 para adimplente
})

print(f"Dados gerados: {df.shape[0]} linhas, {df.shape[1]} colunas.")
print(df.head())
print("\nInformações sobre a variável alvo:")
print(df['default'].value_counts(normalize=True))

# --- 2. Pré-processamento de Dados ---
print("\n2. Pré-processamento de dados...")

# Definir colunas numéricas e categóricas
numerical_cols = ['idade', 'renda_mensal', 'divida_existente', 'score_serasa', 'tempo_emprego_meses', 'num_emprestimos_ativos']
categorical_cols = ['genero', 'estado_civil', 'escolaridade', 'tipo_moradia']

# Separar features (X) e target (y)
X = df.drop('default', axis=1)
y = df['default']

# Divisão em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Criar pipelines de pré-processamento
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler()) # Escalar dados numéricos
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore')) # One-hot encoding para categóricas
])

# Criar um pré-processador combinando as transformações
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

print("Pré-processamento configurado.")

# --- 3. Modelagem Preditiva (XGBoost) ---
print("\n3. Treinando o modelo XGBoost...")

# Criar o pipeline completo: pré-processamento + modelo
model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))])

# Treinar o modelo
model_pipeline.fit(X_train, y_train)

print("Modelo XGBoost treinado com sucesso!")

# --- 4. Avaliação do Modelo ---
print("\n4. Avaliando o modelo...")

# Previsões no conjunto de teste
y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1] # Probabilidade de default
y_pred = model_pipeline.predict(X_test) # Classe predita (0 ou 1)

# AUC-ROC Score
auc_score = roc_auc_score(y_test, y_pred_proba)
print(f"AUC-ROC Score: {auc_score:.4f}")

# Curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (AUC = {auc_score:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Matriz de Confusão
cm = confusion_matrix(y_test, y_pred)
print("\nMatriz de Confusão:")
print(cm)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Não Default', 'Default'],
            yticklabels=['Não Default', 'Default'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

# Relatório de Classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

# --- 5. Explicabilidade do Modelo (SHAP) ---
print("\n5. Calculando valores SHAP para explicabilidade do modelo...")

# Para SHAP, precisamos do modelo treinado e dos dados pré-processados
# É importante usar os dados pré-processados para o SHAP funcionar corretamente com o modelo
explainer = shap.TreeExplainer(model_pipeline.named_steps['classifier'])

# Obter os dados transformados para as previsões
X_test_transformed = model_pipeline.named_steps['preprocessor'].transform(X_test)

# Se X_test_transformed for uma matriz esparsa (Sparse Matrix), converta para densa
if isinstance(X_test_transformed, (np.ndarray, pd.DataFrame)):
    pass
else: # Provavelmente scipy.sparse._csr.csr_matrix
    X_test_transformed = X_test_transformed.toarray()


# Obter os nomes das features após o one-hot encoding
# Isso pode ser um pouco complexo devido ao ColumnTransformer
ohe = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']
cat_feature_names = ohe.get_feature_names_out(categorical_cols)
all_feature_names = numerical_cols + list(cat_feature_names)

# Criar um DataFrame com os dados transformados e os nomes das features para o SHAP
X_test_transformed_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)


# Calcular os valores SHAP
shap_values = explainer.shap_values(X_test_transformed_df)


# Plot sumário SHAP (importância global das features)
print("\nPlotando importâncias SHAP (global):")
shap.summary_plot(shap_values, X_test_transformed_df, plot_type="bar", show=False)
plt.title('Importância Global das Features (SHAP)')
plt.show()

# Plot sumário SHAP (impacto e direção das features)
print("\nPlotando impacto SHAP (direção):")
shap.summary_plot(shap_values, X_test_transformed_df, show=False)
plt.title('Impacto e Direção das Features (SHAP)')
plt.show()

# Plot para uma observação individual (ex: primeira observação do teste)
print("\nPlotando explicabilidade para uma observação individual (primeiro cliente de teste):")
shap.initjs() # Inicializa JS para plots interativos (para uso em Jupyter/Streamlit)
shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_transformed_df.iloc[0,:], show=False, matplotlib=True)
plt.title('Explicabilidade para um Cliente Específico')
plt.show()


print("\n--- Fim do Script de MVP em Python ---")
print("Este script gerou dados, treinou um modelo e avaliou sua performance, além de demonstrar a explicabilidade com SHAP. Agora, estamos prontos para integrar isso ao Streamlit!")

"""# New Section - Metrics of monitoring"""

# metrics_and_monitoring.py

import pandas as pd
import numpy as np
from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

## --- Métricas de Performance e Discriminação Detalhadas ---

def calculate_ks_gini_ap(y_true, y_pred_proba):
    """
    Calcula o KS Statistic, Gini Coefficient (ou Accuracy Ratio) e Average Precision.

    Args:
        y_true (array-like): Valores verdadeiros da variável alvo (0 ou 1).
        y_pred_proba (array-like): Probabilidades previstas pelo modelo para a classe positiva (1).

    Returns:
        dict: Dicionário contendo 'KS_Statistic', 'Gini_Coefficient', 'Average_Precision'.
    """
    # KS Statistic
    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)
    ks_statistic = np.max(np.abs(tpr - fpr))

    # AUC-ROC para Gini
    auc_score = roc_auc_score(y_true, y_pred_proba)
    gini_coefficient = 2 * auc_score - 1

    # Average Precision (AP)
    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)
    average_precision = auc(recall, precision)

    return {
        'KS_Statistic': ks_statistic,
        'Gini_Coefficient': gini_coefficient,
        'Average_Precision': average_precision
    }

def plot_precision_recall_curve(y_true, y_pred_proba, title="Curva Precision-Recall"):
    """
    Plota a Curva Precision-Recall.

    Args:
        y_true (array-like): Valores verdadeiros da variável alvo (0 ou 1).
        y_pred_proba (array-like): Probabilidades previstas pelo modelo para a classe positiva (1).
        title (str): Título do gráfico.

    Returns:
        matplotlib.figure.Figure: Objeto Figure do Matplotlib.
    """
    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)
    ap = auc(recall, precision)

    fig, ax = plt.subplots(figsize=(8, 6))
    ax.plot(recall, precision, color='purple', lw=2, label=f'Precision-Recall (AP = {ap:.2f})')
    ax.set_xlabel('Recall (Sensibilidade)')
    ax.set_ylabel('Precisão')
    ax.set_title(title)
    ax.legend(loc="lower left")
    ax.grid(True)
    return fig

## --- Métricas de Monitoramento e Robustez ---

def calculate_psi(expected_dist, actual_dist):
    """
    Calcula o Population Stability Index (PSI).

    Args:
        expected_dist (pd.Series): Distribuição de frequência (ou porcentagem) esperada.
        actual_dist (pd.Series): Distribuição de frequência (ou porcentagem) atual/observada.

    Returns:
        float: Valor do PSI.
    """
    # Ensure both distributions have the same index and are normalized
    expected_dist = expected_dist / expected_dist.sum()
    actual_dist = actual_dist / actual_dist.sum()

    # Add a small epsilon to avoid division by zero
    epsilon = 1e-6
    expected_dist = expected_dist.apply(lambda x: max(x, epsilon))
    actual_dist = actual_dist.apply(lambda x: max(x, epsilon))

    psi = ((actual_dist - expected_dist) * np.log(actual_dist / expected_dist)).sum()
    return psi

def monitor_psi(df, score_column, bins=10):
    """
    Simula o cálculo de PSI para uma coluna de scores ao longo do tempo.
    Em um cenário real, você teria dados de diferentes períodos (cohorts).
    Aqui, criamos uma 'distribuição esperada' do dataset completo e 'distribuições atuais'
    de subconjuntos simulados.

    Args:
        df (pd.DataFrame): DataFrame contendo a coluna de score.
        score_column (str): Nome da coluna com os scores do modelo.
        bins (int): Número de bins para discretizar os scores.

    Returns:
        dict: Dicionário com resultados de PSI simulados.
    """
    # 1. Definir a distribuição 'esperada' (baseada em todo o df)
    # Discretizar a coluna de scores em bins
    df['score_bin'] = pd.cut(df[score_column], bins=bins, duplicates='drop', include_lowest=True, right=False)
    expected_counts = df['score_bin'].value_counts().sort_index()

    # Simular dados de 'períodos' subsequentes
    # Em um caso real, você carregaria dados de outros meses/trimestres
    n_samples = len(df)
    simulated_periods = {}
    for i in range(1, 4): # Simula 3 períodos adicionais
        # Simula uma ligeira mudança na distribuição para mostrar PSI
        if i == 1: # Pequeno shift
            sim_scores = df[score_column] + np.random.normal(0, 0.01, n_samples)
        elif i == 2: # Médio shift
            sim_scores = df[score_column] + np.random.normal(0, 0.05, n_samples)
        else: # Grande shift
            sim_scores = df[score_column] + np.random.normal(0, 0.1, n_samples)

        sim_df = pd.DataFrame({score_column: sim_scores})
        sim_df['score_bin'] = pd.cut(sim_df[score_column], bins=bins, duplicates='drop', include_lowest=True, right=False)
        # Remove the line that was causing the error: sim_df['score_bin'] = sim_df['score_bin'].cat.add_categories('Missing')
        # Remove the line that was causing the error: sim_df['score_bin'] = sim_df['score_bin'].fillna('Missing') # Handle potential new values outside bins
        sim_counts = sim_df['score_bin'].value_counts().sort_index()

        # Alinhar índices para cálculo do PSI, filling missing bins with 0
        all_bins = pd.Index(expected_counts.index.union(sim_counts.index).drop_duplicates().sort_values())
        exp_aligned = expected_counts.reindex(all_bins, fill_value=0)
        sim_aligned = sim_counts.reindex(all_bins, fill_value=0)

        simulated_periods[f'Periodo_{i}'] = calculate_psi(exp_aligned, sim_aligned)

    return simulated_periods

def plot_vintage_analysis(n_vintages=5):
    """
    Simula e plota uma análise de Vintage (Curva de Safra).
    Em um cenário real, você teria dados de diferentes cohorts de empréstimos.

    Args:
        n_vintages (int): Número de vintages (safra) a simular.

    Returns:
        matplotlib.figure.Figure: Objeto Figure do Matplotlib.
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    months_on_book = np.arange(1, 13) # 12 meses de acompanhamento

    for i in range(n_vintages):
        # Simular taxas de default que aumentam com o tempo, mas variam por vintage
        # Vintages mais recentes podem ter performance ligeiramente diferente
        base_default_rate = 0.01 + (i * 0.005) # Vintages mais novas com default um pouco maior
        default_curve = 1 - np.exp(-0.2 * months_on_book) # Curva de default
        vintage_performance = base_default_rate * default_curve * 100 # Em porcentagem

        # Adicionar um pouco de ruído para parecer mais real
        vintage_performance = vintage_performance + np.random.normal(0, 0.5, len(months_on_book))
        vintage_performance = np.maximum(0, vintage_performance) # Não deixar negativo

        ax.plot(months_on_book, vintage_performance, marker='o', linestyle='-', label=f'Vintage {2025-n_vintages+i}')

    ax.set_title('Análise de Vintage (Taxa de Inadimplência Acumulada)')
    ax.set_xlabel('Meses em Aberto')
    ax.set_ylabel('Taxa de Inadimplência Acumulada (%)')
    ax.set_xticks(months_on_book)
    ax.grid(True)
    ax.legend(title='Safra de Concessão', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    return fig

# Exemplo de uso (for testing locally)
if __name__ == '__main__':
    print("Testando metrics_and_monitoring.py...")
    # Crie dados fictícios para teste
    np.random.seed(42)
    y_true_test = np.random.randint(0, 2, 1000)
    y_pred_proba_test = np.random.rand(1000)

    # Teste de métricas detalhadas
    metrics = calculate_ks_gini_ap(y_true_test, y_pred_proba_test)
    print(f"Métricas calculadas: {metrics}")

    fig_prc = plot_precision_recall_curve(y_true_test, y_pred_proba_test)
    plt.show()

    # Teste de PSI
    df_scores = pd.DataFrame({'scores': np.random.normal(0.5, 0.2, 5000)})
    psi_results = monitor_psi(df_scores, 'scores')
    print(f"Resultados de PSI simulados: {psi_results}")

    # Teste de Vintage
    fig_vintage = plot_vintage_analysis()
    plt.show()

"""# Business Impact  - Measurement Metrics"""

# business_impact_metrics.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

## --- Modelagem de Perdas (LGD, EAD, Expected Loss) ---

def simulate_lgd_ead(n_samples):
    """
    Simula valores de Loss Given Default (LGD) e Exposure at Default (EAD).
    Em um cenário real, estes seriam modelos próprios treinados com dados históricos.

    Args:
        n_samples (int): Número de amostras para simular.

    Returns:
        pd.DataFrame: DataFrame com as colunas 'lgd' e 'ead'.
    """
    # LGD: Valor entre 0 e 1, representando a % perdida (Ex: Beta distribution)
    lgd = np.random.beta(a=2, b=5, size=n_samples) # Distribuição comum para LGD, concentra valores mais baixos

    # EAD: Exposição no momento do default (simula um valor em Reais)
    ead = np.random.normal(loc=15000, scale=5000, size=n_samples)
    ead = np.maximum(1000, ead).round(2) # EAD mínimo de R$1000

    return pd.DataFrame({'lgd': lgd, 'ead': ead})

def calculate_expected_loss(df_with_pd, pd_column='prob_default'):
    """
    Calcula a Perda Esperada (Expected Loss) para cada cliente.
    EL = PD * LGD * EAD

    Args:
        df_with_pd (pd.DataFrame): DataFrame que deve conter a coluna de PD.
        pd_column (str): Nome da coluna com as probabilidades de default (PD).

    Returns:
        pd.DataFrame: O DataFrame original com uma nova coluna 'expected_loss'.
    """
    # Simular LGD e EAD para os mesmos clientes que temos PD
    simulated_lgd_ead = simulate_lgd_ead(len(df_with_pd))
    df_with_pd['lgd'] = simulated_lgd_ead['lgd']
    df_with_pd['ead'] = simulated_lgd_ead['ead']

    df_with_pd['expected_loss'] = df_with_pd[pd_column] * df_with_pd['lgd'] * df_with_pd['ead']
    return df_with_pd

def plot_expected_loss_distribution(df, expected_loss_column='expected_loss'):
    """
    Plota a distribuição da Perda Esperada.

    Args:
        df (pd.DataFrame): DataFrame contendo a coluna de Expected Loss.
        expected_loss_column (str): Nome da coluna com os valores de Expected Loss.

    Returns:
        matplotlib.figure.Figure: Objeto Figure do Matplotlib.
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.histplot(df[expected_loss_column], bins=50, kde=True, ax=ax)
    ax.set_title('Distribuição da Perda Esperada por Cliente')
    ax.set_xlabel('Perda Esperada (R$)')
    ax.set_ylabel('Frequência')
    return fig

## --- Métricas de Rentabilidade Ajustada ao Risco (RORAC/RAROC) ---

def calculate_rorac_raroc(total_expected_loss, capital_allocated, revenue, risk_adjusted=True):
    """
    Calcula o RORAC (Return on Risk-Adjusted Capital) ou RAROC (Risk-Adjusted Return on Capital).
    Para simplificar, vamos assumir que o "capital_allocated" já reflete o risco.
    Em um cenário real, capital alocado seria calculado com base em risco de crédito (VaR, EL).

    Args:
        total_expected_loss (float): Soma das perdas esperadas do portfólio.
        capital_allocated (float): Capital alocado para cobrir os riscos (Regulatório/Econômico).
        revenue (float): Receita bruta gerada pelo portfólio.
        risk_adjusted (bool): Se True, calcula RAROC (Revenue - Expected Loss) / Capital.
                              Se False, calcula RORAC (Revenue / Capital).

    Returns:
        float: O valor do RORAC/RAROC.
    """
    if capital_allocated <= 0:
        return 0 # Evitar divisão por zero

    if risk_adjusted:
        # RAROC = (Revenue - Expected Loss) / Capital
        raroc = (revenue - total_expected_loss) / capital_allocated
        return raroc
    else:
        # RORAC = Revenue / Capital (se capital já é ajustado ao risco)
        # Neste caso, vamos retornar o RAROC mesmo, já que o EL é um componente chave do risco
        rorac = (revenue - total_expected_loss) / capital_allocated
        return rorac # Em uso prático, RAROC é mais comum para modelos de crédito

# Exemplo de uso (para teste local)
if __name__ == '__main__':
    print("Testando business_impact_metrics.py...")

    # Teste de LGD/EAD
    n_test_samples = 100
    sim_lgd_ead = simulate_lgd_ead(n_test_samples)
    print(f"LGD/EAD simulados (head):\n{sim_lgd_ead.head()}")

    # Teste de Expected Loss
    df_test_pd = pd.DataFrame({'prob_default': np.random.rand(n_test_samples)})
    df_test_el = calculate_expected_loss(df_test_pd)
    print(f"Expected Loss (head):\n{df_test_el.head()}")
    fig_el = plot_expected_loss_distribution(df_test_el)
    plt.show()

    # Teste de RORAC/RAROC
    total_el = df_test_el['expected_loss'].sum()
    total_revenue = 200000 # Exemplo de receita
    total_capital = 50000  # Exemplo de capital alocado
    raroc_val = calculate_rorac_raroc(total_el, total_capital, total_revenue, risk_adjusted=True)
    print(f"RAROC calculado: {raroc_val:.2%}") # Formato percentual