# mancredit_streamlit.py (ATUALIZADO com Backtesting e VaR)

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report, precision_recall_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import shap

from streamlit_option_menu import option_menu

# Importar as fun√ß√µes dos arquivos de m√©tricas e impacto de neg√≥cio
# Certifique-se que o nome do arquivo corresponde ao que voc√™ salvou (mancredit_metrics.py e mancredit_businessimpact.py)
from metrics_and_monitoring import calculate_ks_gini_ap, plot_precision_recall_curve, monitor_psi, plot_vintage_analysis
from business_impact_metrics import (
    calculate_expected_loss, 
    plot_expected_loss_distribution,
    calculate_rorac_raroc, 
    simulate_backtesting_performance, 
    calculate_credit_var,
    plot_backtesting_results
)

# --- Configura√ß√µes Iniciais e Branding ---
st.set_page_config(
    layout="wide",
    page_title="MAN Consulting - MVP de Risco de Cr√©dito Avan√ßado",
    initial_sidebar_state="expanded"
)

# Adicionar o logo da MAN Consulting
# Verifique se o arquivo 'logo_man_consulting.png' est√° na mesma pasta do seu script
st.sidebar.image("logo_man_consulting.png", use_column_width=True, caption="MAN Consulting")
st.sidebar.title("MENU PRINCIPAL")

# Menu de Navega√ß√£o na Sidebar
with st.sidebar:
    selected = option_menu(
        menu_title=None,
        options=["An√°lise de Risco", "Sobre a MAN Consulting"],
        icons=["bar-chart-fill", "info-circle-fill"],
        menu_icon="cast",
        default_index=0,
    )

# --- Fun√ß√µes do Aplicativo (Mantidas do c√≥digo anterior) ---

@st.cache_data
def generate_fictitious_data(n_samples=10000):
    np.random.seed(42)
    idade = np.random.randint(18, 70, n_samples)
    renda_mensal = np.random.normal(5000, 2000, n_samples).round(2)
    divida_existente = np.random.normal(15000, 7000, n_samples).round(2)
    score_serasa = np.random.randint(300, 900, n_samples)
    tempo_emprego_meses = np.random.randint(0, 240, n_samples)
    num_emprestimos_ativos = np.random.randint(0, 5, n_samples)
    genero = np.random.choice(['Masculino', 'Feminino'], n_samples)
    estado_civil = np.random.choice(['Solteiro', 'Casado', 'Divorciado', 'Vi√∫vo'], n_samples)
    escolaridade = np.random.choice(['Fundamental', 'M√©dio', 'Superior', 'P√≥s-gradua√ß√£o'], n_samples, p=[0.1, 0.3, 0.4, 0.2])
    tipo_moradia = np.random.choice(['Alugada', 'Propria', 'Financiada'], n_samples)
    prob_default = (1 / (1 + np.exp(
        - (
            0.0005 * (3000 - renda_mensal) +
            0.0001 * divida_existente +
            0.005 * (500 - score_serasa) +
            np.random.normal(0, 0.5, n_samples)
        )
    )))
    default = (np.random.rand(n_samples) < prob_default).astype(int)
    df = pd.DataFrame({
        'idade': idade, 'renda_mensal': np.maximum(500, renda_mensal),
        'divida_existente': np.maximum(0, divida_existente), 'score_serasa': score_serasa,
        'tempo_emprego_meses': tempo_emprego_meses, 'num_emprestimos_ativos': num_emprestimos_ativos,
        'genero': genero, 'estado_civil': estado_civil, 'escolaridade': escolaridade,
        'tipo_moradia': tipo_moradia, 'default': default
    })
    return df

@st.cache_resource
def train_model(df_input):
    numerical_cols = ['idade', 'renda_mensal', 'divida_existente', 'score_serasa', 'tempo_emprego_meses', 'num_emprestimos_ativos']
    categorical_cols = ['genero', 'estado_civil', 'escolaridade', 'tipo_moradia']
    X = df_input.drop('default', axis=1)
    y = df_input['default']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])
    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numerical_cols),
            ('cat', categorical_transformer, categorical_cols)
        ])
    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                     ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))])
    model_pipeline.fit(X_train, y_train)
    ohe = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']
    cat_feature_names = ohe.get_feature_names_out(categorical_cols)
    all_feature_names = numerical_cols + list(cat_feature_names)
    return model_pipeline, X_test, y_test, all_feature_names

# --- Conte√∫do da P√°gina "An√°lise de Risco" ---
if selected == "An√°lise de Risco":
    st.header("An√°lise de Risco de Cr√©dito")
    st.markdown("""
    Esta se√ß√£o apresenta o ciclo completo de modelagem de risco, desde o carregamento dos dados at√© a explicabilidade das previs√µes.
    """)

    st.sidebar.subheader("Carregar Dados")
    data_source = st.sidebar.radio("Escolha a fonte dos dados:", ("Gerar Dados Fict√≠cios", "Upload de Arquivo CSV"))

    df = None
    if data_source == "Gerar Dados Fict√≠cios":
        n_samples_gen = st.sidebar.slider("N√∫mero de clientes fict√≠cios:", 1000, 50000, 10000)
        df = generate_fictitious_data(n_samples_gen)
        st.success(f"Dados fict√≠cios gerados com sucesso! ({n_samples_gen} registros)")
    else:
        uploaded_file = st.sidebar.file_uploader("Fa√ßa o upload do seu arquivo CSV", type=["csv"])
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.success("Arquivo CSV carregado com sucesso!")
            except Exception as e:
                st.error(f"Erro ao carregar o arquivo: {e}")
        else:
            st.info("Por favor, carregue um arquivo CSV para continuar ou selecione 'Gerar Dados Fict√≠cios'.")

    if df is not None:
        st.subheader("Visualiza√ß√£o dos Dados Carregados")
        st.write(df.head())
        st.write(f"Dimens√µes do dataset: {df.shape[0]} linhas, {df.shape[1]} colunas.")
        st.write("Distribui√ß√£o da vari√°vel alvo ('default'):")
        st.write(df['default'].value_counts(normalize=True).apply(lambda x: f"{x:.2%}"))

        st.sidebar.subheader("Treinamento do Modelo")
        if st.sidebar.button("Treinar Modelo de Risco"):
            with st.spinner("Treinando modelo XGBoost e calculando m√©tricas..."):
                model_pipeline, X_test, y_test, all_feature_names = train_model(df.copy())
                st.session_state['model_pipeline'] = model_pipeline
                st.session_state['X_test'] = X_test
                st.session_state['y_test'] = y_test
                st.session_state['all_feature_names'] = all_feature_names
                # Calcular prob_default para todo o df original (para PSI, EL, VaR e Backtesting)
                df['prob_default'] = model_pipeline.predict_proba(df.drop('default', axis=1))[:, 1]
                st.session_state['df_with_prob'] = df # Salva o df com as probabilidades no session_state
            st.sidebar.success("Modelo treinado e pronto para avalia√ß√£o!")

        if 'model_pipeline' in st.session_state:
            st.subheader("Resultados da Modelagem")
            model_pipeline = st.session_state['model_pipeline']
            X_test = st.session_state['X_test']
            y_test = st.session_state['y_test']
            all_feature_names = st.session_state['all_feature_names']
            df_with_prob = st.session_state['df_with_prob']

            y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]

            # --- Novo: Slider para Threshold de Corte ---
            st.markdown("---")
            st.subheader("Ajuste o Limiar de Classifica√ß√£o de Risco")
            st.info("""
            O limiar (threshold) define a partir de qual probabilidade um cliente √© classificado como 'Default' (inadimplente).
            Ajustar este valor muda o equil√≠brio entre detectar inadimplentes reais e evitar classificar bons clientes erroneamente.
            """)
            classification_threshold = st.slider(
                'Defina o Limiar de Probabilidade para Classifica√ß√£o como "Default"',
                min_value=0.01, max_value=0.99, value=0.5, step=0.01,
                help="Clientes com probabilidade de default acima deste valor ser√£o classificados como 'Default'."
            )
            y_pred_thresholded = (y_pred_proba >= classification_threshold).astype(int)

            # M√©trica AUC-ROC (n√£o muda com o threshold)
            auc_score = roc_auc_score(y_test, y_pred_proba)
            st.metric(label="AUC-ROC Score", value=f"{auc_score:.4f}")

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Curva ROC")
                fig_roc, ax_roc = plt.subplots(figsize=(8, 6))
                fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba) # Capturar thresholds
                ax_roc.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (AUC = {auc_score:.2f})')
                ax_roc.plot([0, 1], [0, 1], color='gray', linestyle='--')
                # Adicionar o ponto do threshold na curva ROC
                idx = np.searchsorted(thresholds_roc, classification_threshold, side="right") -1
                if idx >= 0 and idx < len(fpr):
                    ax_roc.plot(fpr[idx], tpr[idx], 'o', color='red', markersize=8, label=f'Threshold={classification_threshold:.2f}')
                ax_roc.set_xlim([0.0, 1.0])
                ax_roc.set_ylim([0.0, 1.05])
                ax_roc.set_xlabel('Taxa de Falsos Positivos (FPR)')
                ax_roc.set_ylabel('Taxa de Verdadeiros Positivos (TPR)')
                ax_roc.set_title('Curva ROC')
                ax_roc.legend(loc="lower right")
                ax_roc.grid(True)
                st.pyplot(fig_roc)

            with col2:
                st.subheader(f"Matriz de Confus√£o (Threshold: {classification_threshold:.2f})")
                cm = confusion_matrix(y_test, y_pred_thresholded) # Usar y_pred_thresholded
                fig_cm, ax_cm = plt.subplots(figsize=(6, 4))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                            xticklabels=['N√£o Default', 'Default'],
                            yticklabels=['N√£o Default', 'Default'], ax=ax_cm)
                ax_cm.set_xlabel('Previsto')
                ax_cm.set_ylabel('Real')
                ax_cm.set_title(f'Matriz de Confus√£o (Threshold: {classification_threshold:.2f})')
                st.pyplot(fig_cm)

            st.subheader(f"Relat√≥rio de Classifica√ß√£o (Threshold: {classification_threshold:.2f})")
            st.text(classification_report(y_test, y_pred_thresholded)) # Usar y_pred_thresholded

            st.markdown("---")
            # --- Novas M√©tricas de Performance e Discrimina√ß√£o ---
            st.header("üìà M√©tricas de Performance e Discrimina√ß√£o Detalhadas")
            advanced_metrics = calculate_ks_gini_ap(y_test, y_pred_proba)

            col_met1, col_met2, col_met3 = st.columns(3)
            with col_met1:
                st.metric(label="KS Statistic", value=f"{advanced_metrics['KS_Statistic']:.4f}")
            with col_met2:
                st.metric(label="Gini Coefficient", value=f"{advanced_metrics['Gini_Coefficient']:.4f}")
            with col_met3:
                st.metric(label="Average Precision (AP)", value=f"{advanced_metrics['Average_Precision']:.4f}")

            st.subheader("Curva Precision-Recall")
            fig_prc = plot_precision_recall_curve(y_test, y_pred_proba)
            st.pyplot(fig_prc)

            st.markdown("---")
            # --- M√©tricas de Monitoramento e Robustez ---
            st.header("üìä M√©tricas de Monitoramento e Robustez")

            st.subheader("Population Stability Index (PSI) - Simulado")
            st.info("""
            O PSI mede o quanto a distribui√ß√£o dos scores (ou features) mudou ao longo do tempo.
            Valores de PSI:
            < 0.1: Sem mudan√ßa significativa (OK)
            0.1 - 0.25: Pequena mudan√ßa (Revis√£o Necess√°ria)
            > 0.25: Grande mudan√ßa (Re-desenvolvimento Prov√°vel)
            Abaixo, uma simula√ß√£o de como o PSI pode se comportar ao longo de diferentes per√≠odos.
            """)
            psi_results = monitor_psi(df_with_prob, 'prob_default')
            for period, psi_val in psi_results.items():
                st.write(f"**{period}:** PSI = **{psi_val:.4f}**")
                if psi_val < 0.1:
                    st.success("‚úÖ Est√°vel")
                elif 0.1 <= psi_val < 0.25:
                    st.warning("‚ö†Ô∏è Aten√ß√£o: Mudan√ßa Moderada")
                else:
                    st.error("üö® Alerta: Mudan√ßa Significativa")


            st.subheader("An√°lise de Vintage - Simulado")
            st.info("A An√°lise de Vintage acompanha a performance (e.g., inadimpl√™ncia acumulada) de diferentes 'safras' de clientes (coortes de concess√£o) ao longo do tempo. Isso revela tend√™ncias de qualidade da carteira.")
            fig_vintage = plot_vintage_analysis(n_vintages=5)
            st.pyplot(fig_vintage)

            # --- Novo: Se√ß√£o de Backtesting ---
            st.markdown("---")
            st.header("üîÑ Backtesting do Modelo")
            st.info("""
            O Backtesting avalia a performance hist√≥rica do modelo, comparando as previs√µes com os resultados reais ao longo do tempo.
            Aqui, simulamos a taxa de default real para diferentes per√≠odos e comparamos com a PD m√©dia prevista.
            """)
            n_periods_backtest = st.slider("N√∫mero de Per√≠odos para Backtest", 3, 24, 12)
            backtest_results_df = simulate_backtesting_performance(df_with_prob, n_periods=n_periods_backtest)
            fig_backtest = plot_backtesting_results(backtest_results_df)
            st.pyplot(fig_backtest)

            st.markdown("---")
            # --- M√©tricas de Neg√≥cio e Impacto Financeiro ---
            st.header("üí∞ M√©tricas de Neg√≥cio e Impacto Financeiro")

            st.subheader("Perda Esperada (Expected Loss)")
            st.info("""
            A Perda Esperada (EL) √© um componente cr√≠tico para precifica√ß√£o de produtos e gest√£o de capital.
            EL = Probabilidade de Default (PD) * Perda Dado Default (LGD) * Exposi√ß√£o no Default (EAD).
            """)
            # Passar o seed para garantir reprodutibilidade da simula√ß√£o de LGD/EAD se houver 'Treinar Modelo' de novo
            df_with_el = calculate_expected_loss(df_with_prob.copy(), 'prob_default', random_seed=42)
            st.write(f"Soma total da Perda Esperada para a amostra: **R$ {df_with_el['expected_loss'].sum():,.2f}**")
            fig_el_dist = plot_expected_loss_distribution(df_with_el)
            st.pyplot(fig_el_dist)

            st.subheader("RAROC (Risk-Adjusted Return on Capital) - Simulado")
            st.info("""
            O RAROC mede o retorno gerado em rela√ß√£o ao capital alocado, ajustado pelo risco.
            √â fundamental para decis√µes estrat√©gicas de investimento e aloca√ß√£o de recursos.
            Quanto maior o RAROC, mais eficiente √© o uso do capital em rela√ß√£o ao risco assumido.
            """)
            total_revenue_sim = st.slider("Receita Total Simulada (R$)", 100000.0, 50000000.0, 10000000.0, step=10000.0) # Ajustado valor inicial
            total_capital_sim = st.slider("Capital Alocado Simulada (R$)", 10000.0, 10000000.0, 2000000.0, step=1000.0) # Ajustado valor inicial

            total_expected_loss_for_raroc = df_with_el['expected_loss'].sum()
            raroc_value = calculate_rorac_raroc(total_expected_loss_for_raroc, total_capital_sim, total_revenue_sim)
            st.metric(label="RAROC", value=f"{raroc_value:.2%}")

            # --- Novo: Se√ß√£o de VaR de Cr√©dito ---
            st.markdown("---")
            st.header("üìâ VaR (Value at Risk) de Cr√©dito")
            st.info("""
            O VaR de Cr√©dito estima a perda m√°xima potencial de um portf√≥lio de cr√©dito em um determinado horizonte de tempo,
            com um certo n√≠vel de confian√ßa. Ele ajuda a quantificar o capital necess√°rio para cobrir perdas inesperadas.
            """)
            col_var_input, col_var_output = st.columns(2)
            with col_var_input:
                var_confidence = st.slider("N√≠vel de Confian√ßa do VaR (%)", 90, 99, 99, step=1)
                n_simulations_var = st.slider("N√∫mero de Simula√ß√µes Monte Carlo", 1000, 20000, 10000)

            # Reutilizar df_with_el que j√° tem prob_default, lgd, ead
            var_value, fig_var_dist = calculate_credit_var(
                df_with_el[['prob_default', 'lgd', 'ead']],
                confidence_level=var_confidence/100,
                n_simulations=n_simulations_var,
                random_seed=42 # Para reprodutibilidade
            )
            with col_var_output:
                st.metric(label=f"VaR de Cr√©dito {var_confidence}%", value=f"R$ {var_value:,.2f}")
            st.pyplot(fig_var_dist)


            # --- Explicabilidade (SHAP) ---
            st.markdown("---")
            st.header("üß† Explicabilidade do Modelo (SHAP)")
            st.markdown("""
            **SHAP (SHapley Additive exPlanations)** nos ajuda a entender como cada caracter√≠stica (feature) impacta a previs√£o do modelo.
            """)
            explainer = shap.TreeExplainer(model_pipeline.named_steps['classifier'])
            X_test_transformed = model_pipeline.named_steps['preprocessor'].transform(X_test)
            if isinstance(X_test_transformed, (np.ndarray, pd.DataFrame)):
                X_test_transformed_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)
            else:
                X_test_transformed_df = pd.DataFrame(X_test_transformed.toarray(), columns=all_feature_names)
            shap_values = explainer.shap_values(X_test_transformed_df)

            col_shap1, col_shap2 = st.columns(2)
            with col_shap1:
                st.write("##### Import√¢ncia Global das Features (SHAP Bar Plot)")
                fig_shap_bar, ax_shap_bar = plt.subplots(figsize=(10, 6))
                shap.summary_plot(shap_values, X_test_transformed_df, plot_type="bar", show=False)
                st.pyplot(fig_shap_bar)
            with col_shap2:
                st.write("##### Impacto e Dire√ß√£o das Features (SHAP Beeswarm Plot)")
                fig_shap_beeswarm, ax_shap_beeswarm = plt.subplots(figsize=(10, 6))
                shap.summary_plot(shap_values, X_test_transformed_df, show=False)
                st.pyplot(fig_shap_beeswarm)

            st.markdown("---")
            st.subheader("Simulador de Risco para um Novo Cliente")
            st.markdown("Ajuste as caracter√≠sticas abaixo para ver a probabilidade de default para um cliente hipot√©tico.")

            input_idade = st.slider('Idade', 18, 70, 30)
            input_renda_mensal = st.slider('Renda Mensal (R$)', 500.0, 20000.0, 5000.0)
            input_divida_existente = st.slider('D√≠vida Existente (R$)', 0.0, 50000.0, 10000.0)
            input_score_serasa = st.slider('Score Serasa', 300, 900, 700)
            input_tempo_emprego_meses = st.slider('Tempo de Emprego (Meses)', 0, 240, 60)
            input_num_emprestimos_ativos = st.slider('N√∫mero de Empr√©stimos Ativos', 0, 5, 1)
            input_genero = st.selectbox('G√™nero', ['Masculino', 'Feminino'])
            input_estado_civil = st.selectbox('Estado Civil', ['Solteiro', 'Casado', 'Divorciado', 'Vi√∫vo'])
            input_escolaridade = st.selectbox('Escolaridade', ['Fundamental', 'M√©dio', 'Superior', 'P√≥s-gradua√ß√£o'])
            input_tipo_moradia = st.selectbox('Tipo de Moradia', ['Alugada', 'Propria', 'Financiada'])

            new_client_data = pd.DataFrame({
                'idade': [input_idade], 'renda_mensal': [input_renda_mensal],
                'divida_existente': [input_divida_existente], 'score_serasa': [input_score_serasa],
                'tempo_emprego_meses': [input_tempo_emprego_meses], 'num_emprestimos_ativos': [input_num_emprestimos_ativos],
                'genero': [input_genero], 'estado_civil': [input_estado_civil], 'escolaridade': [input_escolaridade],
                'tipo_moradia': [input_tipo_moradia],
            })

            new_client_proba = model_pipeline.predict_proba(new_client_data)[:, 1][0]
            st.write(f"##### Probabilidade de Inadimpl√™ncia para este cliente: **{new_client_proba:.2%}**")

            st.write("##### Explicabilidade da Previs√£o para este Cliente (SHAP Force Plot)")
            explainer_single = shap.TreeExplainer(model_pipeline.named_steps['classifier'])
            single_client_transformed = model_pipeline.named_steps['preprocessor'].transform(new_client_data)
            if isinstance(single_client_transformed, (np.ndarray, pd.DataFrame)):
                single_client_transformed_df = pd.DataFrame(single_client_transformed, columns=all_feature_names)
            else:
                single_client_transformed_df = pd.DataFrame(single_client_transformed.toarray(), columns=all_feature_names)
            shap_values_single = explainer_single.shap_values(single_client_transformed_df)[0]

            fig_force_plot = shap.force_plot(explainer_single.expected_value, shap_values_single, single_client_transformed_df.iloc[0], matplotlib=True, show=False)
            st.pyplot(fig_force_plot, bbox_inches='tight')
            st.markdown("---")
            st.markdown("**Observa√ß√£o:** No gr√°fico acima, valores em vermelho empurram a previs√£o para cima (maior risco), enquanto valores em azul a empurram para baixo (menor risco). A base (E[f(x)]) √© a previs√£o m√©dia do modelo.")
        else:
            st.warning("Por favor, clique em 'Treinar Modelo de Risco' na barra lateral para iniciar a an√°lise.")
    else:
        st.info("Carregue seus dados ou gere dados fict√≠cios para come√ßar.")

# --- Conte√∫do da P√°gina "Sobre a MAN Consulting" ---
elif selected == "Sobre a MAN Consulting":
    st.header("Sobre a MAN Consulting")
    st.markdown("""
    A **MAN Consulting** √© uma consultoria independente especializada em **modelagem preditiva, avalia√ß√£o de risco de cr√©dito e precifica√ß√£o din√¢mica** para institui√ß√µes financeiras, fintechs e plataformas de cr√©dito na Am√©rica Latina, EUA e Europa.
    """)

    st.subheader("Nossa Miss√£o")
    st.markdown("""
    Entregar intelig√™ncia anal√≠tica aplicada ao cr√©dito, com solu√ß√µes que combinam:
    * **Rigor estat√≠stico e compliance regulat√≥rio;**
    * **Rapidez na implementa√ß√£o com entregas modulares;**
    * **Resultados mensur√°veis, como redu√ß√£o de inadimpl√™ncia e otimiza√ß√£o de pricing por risco.**
    """)

    st.subheader("Sobre o Fundador")
    st.markdown("""
    Fundada por **Matheus Nascimento**, profissional com mais de 7 anos de experi√™ncia no mercado financeiro, a MAN Consulting une vis√£o estrat√©gica de neg√≥cios com t√©cnicas avan√ßadas de an√°lise quantitativa, oferecendo solu√ß√µes customizadas para originadores de cr√©dito, plataformas P2P, SCDs e gestoras de carteiras.

    Matheus atua como Credit and Data Analyst em gestora com mais de USD 300 milh√µes sob gest√£o, sendo respons√°vel por:
    * Desenvolvimento de modelos de risco de cr√©dito e ferramentas de gest√£o para carteiras de cr√©dito e ativos financeiros;
    * Estrutura√ß√£o de modelos macroecon√¥micos preditivos para avalia√ß√£o de condi√ß√µes de cr√©dito;
    * Implementa√ß√£o de pipelines de dados e automa√ß√£o de rotinas anal√≠ticas com Python, SQL e modelos quantitativos.

    Matheus acumula passagens por research houses e tesourarias de investimentos, com track record de gera√ß√£o de alfa superior ao benchmark em diversas estrat√©gias. √â Mestre em M√©todos Quantitativos e Pesquisa Operacional pelo ITA, com P√≥s-gradua√ß√£o em Engenharia Financeira pela FIA Business School.
    """)

    st.subheader("Conecte-se Conosco")
    st.markdown("""
    Ficaremos felizes em discutir suas necessidades e como a MAN Consulting pode ajudar sua empresa a otimizar a gest√£o de risco e as decis√µes de cr√©dito.
    """)
    st.markdown("üì© **Contato:** matheus.nascimento@manconsulting.ai")
    st.markdown("üîó **LinkedIn:** [Matheus Nascimento](https://www.linkedin.com/in/matheus-az-nascimento/)")